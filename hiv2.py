# -*- coding: utf-8 -*-
"""HIV2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qrKjoPA6Vqcj7FeU_lxleJX42WDsqfXK
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
df = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')

df.head()

df.isnull().sum()

# Load the merged data
df = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')

# Filter for individual-level records where HIV_Status is not null
# This aligns with the approach used in previous modeling cells
df_cleaned = df[df['HIV_Status'].notnull()].copy()

# Identify columns with a high percentage of missing values
# These columns often relate to aggregated data not used in individual-level prediction
missing_cols = ['HIV_Prevalence_%_ages_15_49', 'Estimated_New_HIV_Infections',
                'AIDS_Related_Deaths', 'ART_Coverage_%']

# Drop the identified columns from the cleaned dataset
df_cleaned = df_cleaned.drop(columns=missing_cols)

# Convert relevant columns to appropriate types as done in modeling cells
df_cleaned['HIV_Status'] = df_cleaned['HIV_Status'].astype(int)
df_cleaned['On_ART'] = df_cleaned['On_ART'].astype(int)
df_cleaned['Age'] = df_cleaned['Age'].astype(int)

print("Cleaned dataset info:")
df_cleaned.info()
print("\nNull values after cleaning:")
print(df_cleaned.isnull().sum())
print("\nHead of the cleaned dataset:")
print(df_cleaned.head())

df.isnull().sum()

# This cell had a syntax error and an incorrect usage of fillna.
# Based on the previous steps, columns with a large number of missing values
# (like 'HIV_Prevalence_%_ages_15_49', 'Estimated_New_HIV_Infections',
# 'AIDS_Related_Deaths', 'ART_Coverage_%') are best handled by dropping them
# for individual-level analysis, which was successfully performed in cell yvJ2nQnf5K3E.
# If you specifically wanted to fill these columns with 0, the correct syntax would be:
# df[['HIV_Prevalence_%_ages_15_49', 'Estimated_New_HIV_Infections',
#     'AIDS_Related_Deaths', 'ART_Coverage_%']].fillna(0, inplace=True)

# ---
# HIV Risk Prediction in Bangladesh â€“ Clean & Actionable Version
# Target: Individual-level HIV risk (binary: 0/1) + interpretable insights
# Data: Synthetic individual records + behavioral logic from PSE 2023
# ---

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    precision_recall_curve,
    auc,
    recall_score,
    f1_score
)
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# Optional: install if not present
# !pip install imbalanced-learn shap

from imblearn.over_sampling import SMOTE





# Keep only individual-level columns (drop aggregated metrics if any)
cols_needed = ['District', 'Age', 'Sex', 'Transmission_Route', 'On_ART', 'Viral_Load', 'HIV_Status']
df = df[cols_needed].copy()

# Drop rows with missing HIV_Status (should be none, but safe)
df = df.dropna(subset=['HIV_Status'])
df['HIV_Status'] = df['HIV_Status'].astype(int)

# ----------------------------
# 2. FEATURE ENGINEERING (Behavioral Risk Signals)
# ----------------------------

# Based on PSE 2023 insights:
# - PWID in Dhaka/Narayanganj â†’ high risk
# - Low condom use, untested, young age â†’ risk
# - Not on ART + high viral load â†’ proxy for late diagnosis

df['Is_PWID'] = (df['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df['Is_MSM_MS'] = (df['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
df['High_Viral_Load'] = (df['Viral_Load'] > 50000).astype(int)  # Arbitrary clinical threshold
df['Not_On_ART'] = (df['On_ART'] == 0).astype(int)
df['Young_Age'] = (df['Age'] < 25).astype(int)

# High-risk districts (from PSE: Dhaka, Narayanganj >5% among PWID)
high_risk_districts = ['Dhaka', 'Narayanganj']
df['High_Risk_District'] = df['District'].isin(high_risk_districts).astype(int)

# Behavioral risk score (simple additive index)
df['Behavioral_Risk_Score'] = (
    df['Is_PWID'] +
    df['Is_MSM_MS'] +
    df['High_Viral_Load'] +
    df['Not_On_ART'] +
    df['Young_Age'] +
    df['High_Risk_District']
)

# Final feature set
feature_cols = [
    'Age', 'Is_PWID', 'Is_MSM_MS', 'High_Viral_Load',
    'Not_On_ART', 'Young_Age', 'High_Risk_District', 'Behavioral_Risk_Score'
]

X = df[feature_cols]
y = df['HIV_Status']

# ----------------------------
# 3. TRAIN/TEST SPLIT
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ----------------------------
# 4. HANDLE CLASS IMBALANCE WITH SMOTE
# ----------------------------
print("Original class distribution:", np.bincount(y_train))
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)
print("After SMOTE:", np.bincount(y_train_bal))

# ----------------------------
# 5. MODEL: LOGISTIC REGRESSION (Interpretable)
# ----------------------------
scaler = StandardScaler()
X_train_bal_scaled = scaler.fit_transform(X_train_bal)
X_test_scaled = scaler.transform(X_test)

model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train_bal_scaled, y_train_bal)

# ----------------------------
# 6. EVALUATION (Focus on Minority Class)
# ----------------------------
y_pred = model.predict(X_test_scaled)
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]

print("\n=== Classification Report (HIV Risk Prediction) ===")
print(classification_report(y_test, y_pred, target_names=['HIV-', 'HIV+']))

# Precision-Recall AUC (better than ROC for imbalanced data)
precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)
print(f"\nPrecision-Recall AUC: {pr_auc:.3f}")

# ----------------------------
# 7. INTERPRETABILITY: SHAP VALUES
# ----------------------------
explainer = shap.LinearExplainer(model, X_train_bal_scaled)
shap_values = explainer.shap_values(X_test_scaled)

# Plot global feature importance
shap.summary_plot(shap_values, X_test, feature_names=feature_cols, show=False)
plt.title("SHAP: Feature Importance for HIV Risk")
plt.tight_layout()
plt.show()

# ----------------------------
# 8. OUTPUT: RISK SCORES FOR HIGH-RISK INDIVIDUALS
# ----------------------------
df_test = X_test.copy()
df_test['HIV_Status_True'] = y_test.values
df_test['HIV_Risk_Prob'] = y_pred_proba
df_test['Predicted_HIV'] = y_pred

# Top 10 highest-risk individuals (true negatives but high predicted risk)
high_risk_candidates = df_test[
    (df_test['HIV_Status_True'] == 0) & (df_test['HIV_Risk_Prob'] > 0.7)
].sort_values('HIV_Risk_Prob', ascending=False).head(10)

print("\n=== Top 10 High-Risk Individuals (Prioritize for Testing) ===")
print(high_risk_candidates[['HIV_Risk_Prob'] + feature_cols])

# ---
# HIV Risk Prediction in Bangladesh â€” Using YOUR merged_df correctly
# Focus ONLY on individual-level records (where HIV_Status is available)
# ---

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, confusion_matrix, precision_recall_curve, auc
)
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import shap



# âœ… CRITICAL: Filter ONLY individual-level rows (where HIV_Status exists)
individual_data = mergdata[mergdata['HIV_Status'].notnull()].copy()
print(f"Using {len(individual_data)} individual-level records.")

# Fix data types (HIV_Status was float due to NaNs in full mergdata)
individual_data['HIV_Status'] = individual_data['HIV_Status'].astype(int)
individual_data['On_ART'] = individual_data['On_ART'].astype(int)
individual_data['Age'] = individual_data['Age'].astype(int)

# ----------------------------
# Feature Engineering (behavioral + contextual)
# ----------------------------

# Transmission risk groups (from PSE report logic)
individual_data['Is_PWID'] = (individual_data['Transmission_Route'] == 'Injecting Drug Use').astype(int)
individual_data['Is_MSM_MS'] = (individual_data['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
individual_data['Is_FSW'] = (individual_data['Transmission_Route'] == 'Heterosexual').astype(int)  # proxy
individual_data['High_Viral_Load'] = (individual_data['Viral_Load'] > 50000).astype(int)
individual_data['Not_On_ART'] = (individual_data['On_ART'] == 0).astype(int)
individual_data['Young_Age'] = (individual_data['Age'] < 25).astype(int)

# High-risk districts (from PSE size estimates: Dhaka, Narayanganj, etc.)
high_risk_districts = ['Dhaka', 'Narayanganj', 'Gazipur', 'Rangpur', 'Sylhet']
individual_data['High_Risk_District'] = individual_data['District'].isin(high_risk_districts).astype(int)

# Final features
feature_cols = [
    'Age', 'Is_PWID', 'Is_MSM_MS', 'Is_FSW',
    'High_Viral_Load', 'Not_On_ART', 'Young_Age', 'High_Risk_District'
]

X = individual_data[feature_cols]
y = individual_data['HIV_Status']

# ----------------------------
# Train/Test Split
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ----------------------------
# Handle Class Imbalance with SMOTE
# ----------------------------
print("Before SMOTE:", np.bincount(y_train))
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)
print("After SMOTE:", np.bincount(y_train_bal))

# ----------------------------
# Train Interpretable Model
# ----------------------------
scaler = StandardScaler()
X_train_bal_scaled = scaler.fit_transform(X_train_bal)
X_test_scaled = scaler.transform(X_test)

model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train_bal_scaled, y_train_bal)

# ----------------------------
# Evaluate (Focus on Minority Class!)
# ----------------------------
y_pred = model.predict(X_test_scaled)
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]

print("\n=== Classification Report ===")
print(classification_report(y_test, y_pred, target_names=['HIV-', 'HIV+']))

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)
print(f"\nPrecision-Recall AUC: {pr_auc:.3f}")

# ----------------------------
# Explain Predictions (SHAP)
# ----------------------------
explainer = shap.LinearExplainer(model, X_train_bal_scaled)
shap_values = explainer.shap_values(X_test_scaled[:100])  # sample for speed

plt.figure(figsize=(8,5))
shap.summary_plot(shap_values, X_test.iloc[:100], feature_names=feature_cols, show=False)
plt.title("Top HIV Risk Drivers (SHAP)")
plt.tight_layout()
plt.show()

# ---
# HIV Risk Mapping + PSE Prior + Export for Outreach (SafeRoads-style)
# ---

# Install contextily if not already installed
!pip install contextily

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import geopandas as gpd
import contextily as ctx

# ----------------------------
# 1. LOAD & FILTER DATA
# ----------------------------

df_ind = mergdata[mergdata['HIV_Status'].notnull()].copy()
df_ind['HIV_Status'] = df_ind['HIV_Status'].astype(int)
df_ind['On_ART'] = df_ind['On_ART'].astype(int)

# Assign unique ID
df_ind['Individual_ID'] = df_ind.index

# ----------------------------
# 2. FEATURE ENGINEERING (PSE-Informed)
# ----------------------------
df_ind['Is_PWID'] = (df_ind['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df_ind['Is_MSM_MS'] = (df_ind['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
df_ind['High_Viral_Load'] = (df_ind['Viral_Load'] > 50000).astype(int)
df_ind['Not_On_ART'] = (df_ind['On_ART'] == 0).astype(int)
df_ind['Young_Age'] = (df_ind['Age'] < 25).astype(int)

# ----------------------------
# 3. LOAD PSE PREVALENCE PRIORS BY DISTRICT & GROUP
# ----------------------------
pse_prior = {
    'Dhaka': 0.052,
    'Narayanganj': 0.051,
    # Add more if available; else use national averages
}
national_prior_pw = 0.041   # PWID
national_prior_msm = 0.015  # MSM
national_prior_fsw = 0.002  # FSW

def get_prior(row):
    district = row['District']
    if row['Is_PWID']:
        return pse_prior.get(district, national_prior_pw)
    elif row['Is_MSM_MS']:
        return pse_prior.get(district, national_prior_msm)
    else:
        return national_prior_fsw

df_ind['PSE_Prior'] = df_ind.apply(get_prior, axis=1)

# ----------------------------
# 4. TRAIN MODEL (same as before)
# ----------------------------
feature_cols = ['Age', 'Is_PWID', 'Is_MSM_MS', 'High_Viral_Load', 'Not_On_ART', 'Young_Age']
X = df_ind[feature_cols]
y = df_ind['HIV_Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

scaler = StandardScaler()
X_train_bal_scaled = scaler.fit_transform(X_train_bal)
X_full_scaled = scaler.transform(X)

model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train_bal_scaled, y_train_bal)

# Predict on FULL dataset
df_ind['Model_Risk'] = model.predict_proba(X_full_scaled)[:, 1]

# ----------------------------
# 5. BAYESIAN RISK CALIBRATION (Add PSE Prior)
# ----------------------------
PRIOR_WEIGHT = 0.3  # Tune: higher = trust PSE more

df_ind['Calibrated_Risk'] = (
    df_ind['Model_Risk'] + PRIOR_WEIGHT * df_ind['PSE_Prior']
) / (1 + PRIOR_WEIGHT)

df_ind['Risk_Category'] = pd.cut(
    df_ind['Calibrated_Risk'],
    bins=[0, 0.3, 0.7, 1.0],
    labels=['Low', 'Medium', 'High']
)

# ----------------------------
# 6. GENERATE RISK FACTOR EXPLANATIONS
# ----------------------------
def get_top_risk_factors(row, features=feature_cols):
    factors = []
    if row['Is_PWID']: factors.append('PWID')
    if row['Is_MSM_MS']: factors.append('MSM/MSW')
    if row['High_Viral_Load']: factors.append('High Viral Load')
    if row['Not_On_ART']: factors.append('Not on ART')
    if row['Young_Age']: factors.append('Age < 25')
    return '; '.join(factors[:3]) if factors else 'None'

df_ind['Top_3_Risk_Factors'] = df_ind.apply(get_top_risk_factors, axis=1)

# ----------------------------
# 7. EXPORT FOR OUTREACH TEAMS
# ----------------------------
outreach_df = df_ind[[
    'Individual_ID', 'District', 'Age', 'Sex', 'Transmission_Route',
    'Calibrated_Risk', 'Risk_Category', 'Top_3_Risk_Factors'
]].copy()

outreach_df['Recommended_Action'] = np.where(
    outreach_df['Risk_Category'] == 'High',
    'Urgent HIV test + counseling + ART readiness assessment',
    np.where(
        outreach_df['Risk_Category'] == 'Medium',
        'HIV test + risk reduction counseling',
        'Routine screening'
    )
)

# Save
outreach_df.to_csv('/content/drive/MyDrive/HIV_Outreach_Team_List.csv', index=False)
print("âœ… Exported HIV risk list for outreach teams!")

# ----------------------------
# 8. MAP HIGH-RISK INDIVIDUALS BY DISTRICT
# ----------------------------
district_risk = df_ind.groupby('District').agg(
    Mean_Calibrated_Risk=('Calibrated_Risk', 'mean'),
    High_Risk_Count=('Risk_Category', lambda x: (x == 'High').sum()),
    Total_Individuals=('Individual_ID', 'count')
).reset_index()

# Load Bangladesh district geo (you can download from DIVA-GIS or use a public shapefile)
# For now, simulate with available districts
print("\n=== Top 10 Highest-Risk Districts ===")
print(district_risk.sort_values('Mean_Calibrated_Risk', ascending=False).head(10))

# Optional: Plot if you have a GeoJSON
# bangladesh = gpd.read_file('/content/drive/MyDrive/bd_districts.geojson')
# merged = bangladesh.merge(district_risk, on='District')
# ax = merged.plot(column='Mean_Calibrated_Risk', legend=True, cmap='Reds', figsize=(10,12))
# ctx.add_basemap(ax, crs=merged.crs, source=ctx.providers.CartoDB.Positron)
# plt.title("HIV Risk Hotspots in Bangladesh (Calibrated with PSE Prior)")
# plt.savefig('/content/drive/MyDrive/HIV_Risk_Map_Bangladesh.png', dpi=150, bbox_inches='tight')

# HIV Risk Prediction System for Bangladesh
# - Uses PSE 2023 behavioral insights as features & priors
# - Safe filtering: only individual-level rows with HIV_Status
# - Calibrated risk + geospatial export + outreach-ready output

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

# ----------------------------
# 1. LOAD & FILTER DATA
# ----------------------------
#mergdata = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')

# Only keep individual-level records (HIV_Status not null)
df = mergdata[mergdata['HIV_Status'].notnull()].copy()
df['HIV_Status'] = df['HIV_Status'].astype(int)
df['On_ART'] = df['On_ART'].astype(int)
df['Age'] = df['Age'].astype(int)

print(f"âœ… Using {len(df)} individual-level records for modeling.")

# ----------------------------
# 2. ENGINEER BEHAVIORAL RISK FEATURES (PSE 2023-BASED)
# ----------------------------
# Transmission groups
df['Is_PWID'] = (df['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df['Is_MSM_MS'] = (df['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
df['Is_FSW'] = (df['Transmission_Route'] == 'Heterosexual') & (df['Sex'] == 'Female')

# Clinical & demographic risks
df['High_Viral_Load'] = (df['Viral_Load'] > 50000).astype(int)
df['Not_On_ART'] = (df['On_ART'] == 0).astype(int)
df['Young_Age'] = (df['Age'] < 25).astype(int)

# PSE-identified high-risk districts (PWID prevalence >5%)
high_risk_districts = ['Dhaka', 'Narayanganj']
df['High_Risk_District'] = df['District'].isin(high_risk_districts).astype(int)

feature_cols = [
    'Is_PWID', 'Is_MSM_MS', 'Is_FSW',
    'High_Viral_Load', 'Not_On_ART', 'Young_Age', 'High_Risk_District'
]

X = df[feature_cols]
y = df['HIV_Status']

# ----------------------------
# 3. TRAIN MODEL WITH SMOTE
# ----------------------------
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

scaler = StandardScaler()
X_train_bal_scaled = scaler.fit_transform(X_train_bal)
X_full_scaled = scaler.transform(X)

model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train_bal_scaled, y_train_bal)

# ----------------------------
# 4. ADD PSE PREVALENCE PRIOR (Bayesian Calibration)
# ----------------------------
# PSE 2023 prevalence (IBBS 2020):
PSE_PREV = {
    'PWID': 0.041,
    'PWID_Dhaka_Narayanganj': 0.052,
    'MSM': 0.015,
    'FSW': 0.002
}

def get_pse_prior(row):
    if row['Is_PWID']:
        if row['District'] in ['Dhaka', 'Narayanganj']:
            return PSE_PREV['PWID_Dhaka_Narayanganj']
        else:
            return PSE_PREV['PWID']
    elif row['Is_MSM_MS']:
        return PSE_PREV['MSM']
    elif row['Is_FSW']:
        return PSE_PREV['FSW']
    else:
        return 0.001  # baseline

df['PSE_Prior'] = df.apply(get_pse_prior, axis=1)

# Calibrate: blend model output with epidemiological prior
model_risk = model.predict_proba(X_full_scaled)[:, 1]
PRIOR_WEIGHT = 0.4  # trust PSE moderately
df['Calibrated_Risk'] = (model_risk + PRIOR_WEIGHT * df['PSE_Prior']) / (1 + PRIOR_WEIGHT)

df['Risk_Level'] = pd.cut(
    df['Calibrated_Risk'],
    bins=[0, 0.3, 0.7, 1.0],
    labels=['Low', 'Medium', 'High']
)

# ----------------------------
# 5. GENERATE ACTIONABLE OUTPUT FOR OUTREACH
# ----------------------------
def get_top_risk_factors(row):
    factors = []
    if row['Is_PWID']: factors.append('PWID')
    if row['Is_MSM_MS']: factors.append('MSM/MSW')
    if row['Is_FSW']: factors.append('FSW')
    if row['High_Viral_Load']: factors.append('High_Viral_Load')
    if row['Not_On_ART']: factors.append('Not on ART')
    if row['Young_Age']: factors.append('Age <25')
    if row['High_Risk_District']: factors.append('High-Risk District')
    return '; '.join(factors[:3]) if factors else 'Low behavioral risk'

df['Top_Risk_Factors'] = df.apply(get_top_risk_factors, axis=1)

# Recommended action
df['Recommended_Action'] = np.where(
    df['Risk_Level'] == 'High',
    'Urgent HIV test + ART linkage + harm reduction',
    np.where(
        df['Risk_Level'] == 'Medium',
        'HIV counseling + condom/syringe provision',
        'Routine screening'
    )
)

# ----------------------------
# 6. EXPORT FILES
# ----------------------------
# A. Individual-level risk list (for field teams)
outreach = df[[
    'District', 'Age', 'Sex', 'Transmission_Route',
    'Calibrated_Risk', 'Risk_Level', 'Top_Risk_Factors', 'Recommended_Action'
]].sort_values('Calibrated_Risk', ascending=False)

outreach.to_csv('/content/drive/MyDrive/HIV_Risk_List_For_Outreach.csv', index=False)

# B. District-level summary (for program managers)
district_summary = df.groupby('District').agg(
    Mean_Calibrated_Risk=('Calibrated_Risk', 'mean'),
    High_Risk_Count=('Risk_Level', lambda x: (x == 'High').sum()),
    Total_Screened=('District', 'count')
).reset_index().sort_values('Mean_Calibrated_Risk', ascending=False)

district_summary.to_csv('/content/drive/MyDrive/HIV_District_Risk_Summary.csv', index=False)

print("âœ… Exported:")
print("   - HIV_Risk_List_For_Outreach.csv")
print("   - HIV_District_Risk_Summary.csv")

# ----------------------------
# 7. (Optional) Plot Top 10 Highest-Risk Districts
# ----------------------------
import matplotlib.pyplot as plt
top10 = district_summary.head(10)
plt.figure(figsize=(10,6))
plt.barh(top10['District'][::-1], top10['Mean_Calibrated_Risk'][::-1], color='crimson')
plt.xlabel('Mean Calibrated HIV Risk')
plt.title('Top 10 Highest-Risk Districts for HIV (Bangladesh)')
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/HIV_Top10_Districts.png', dpi=150)
plt.show()

# ---
# HIV Risk Prediction in Bangladesh â€” Full 10-Model Benchmark + Combined ROC
# Metrics: Precision, Recall, Accuracy, F1, ROC-AUC, per-class scores
# ---

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    classification_report,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    roc_curve,
    confusion_matrix
)
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import warnings
warnings.filterwarnings('ignore')

# ----------------------------
# 1. LOAD & FILTER DATA
# ----------------------------
#mergdata = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')
df = mergdata[mergdata['HIV_Status'].notnull()].copy()
df['HIV_Status'] = df['HIV_Status'].astype(int)
print(f"âœ… Using {len(df)} individual records. HIV+ rate: {df['HIV_Status'].mean():.1%}")

# ----------------------------
# 2. FEATURE ENGINEERING (PSE-Informed)
# ----------------------------
df['Is_PWID'] = (df['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df['Is_MSM_MS'] = (df['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
df['High_Viral_Load'] = (df['Viral_Load'] > 50000).astype(int)
df['Not_On_ART'] = (df['On_ART'] == 0).astype(int)
df['Young'] = (df['Age'] < 25).astype(int)
high_risk_districts = ['Dhaka', 'Narayanganj']
df['High_Risk_District'] = df['District'].isin(high_risk_districts).astype(int)

feature_cols = ['Is_PWID', 'Is_MSM_MS', 'High_Viral_Load', 'Not_On_ART', 'Young', 'High_Risk_District', 'Age']
X = df[feature_cols]
y = df['HIV_Status']

# ----------------------------
# 3. SPLIT DATA
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ----------------------------
# 4. DEFINE MODELS
# ----------------------------
pos_weight = sum(y_train == 0) / sum(y_train == 1)

models = {
    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),
    'Decision Tree': DecisionTreeClassifier(class_weight='balanced', max_depth=6, random_state=42),
    'Random Forest': RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),
    'Naive Bayes': GaussianNB(),
    'XGBoost': xgb.XGBClassifier(scale_pos_weight=pos_weight, random_state=42, eval_metric='logloss'),
    'LightGBM': lgb.LGBMClassifier(class_weight='balanced', random_state=42, verbose=-1),
    'CatBoost': CatBoostClassifier(class_weights=[1, pos_weight], random_state=42, verbose=0),
    'SVM': SVC(class_weight='balanced', probability=True, random_state=42),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'MLP': MLPClassifier(hidden_layer_sizes=(64,32), max_iter=500, random_state=42)
}

# ----------------------------
# 5. TRAIN & EVALUATE ALL MODELS
# ----------------------------
results = []
scaler = StandardScaler()
plt.figure(figsize=(10, 8))

for name, model in models.items():
    print(f"Training {name}...")

    # Handle scaling
    if name in ['SVM', 'KNN', 'MLP']:
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        train_X, test_X = X_train_scaled, X_test_scaled
    else:
        train_X, test_X = X_train, X_test

    # Handle SMOTE for models without class_weight
    if name in ['Naive Bayes', 'KNN', 'MLP']:
        smote = SMOTE(random_state=42)
        train_X, train_y = smote.fit_resample(train_X, y_train)
    else:
        train_y = y_train

    # Train
    model.fit(train_X, train_y)

    # Predict
    y_pred = model.predict(test_X)
    y_proba = model.predict_proba(test_X)[:, 1]

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_proba)

    results.append({
        'Model': name,
        'Accuracy': acc,
        'Precision (HIV+)': prec,
        'Recall (HIV+)': rec,
        'F1-Score': f1,
        'ROC-AUC': roc_auc
    })

    # Plot ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

# ----------------------------
# 6. DISPLAY FULL RESULTS
# ----------------------------
results_df = pd.DataFrame(results).sort_values('Recall (HIV+)', ascending=False)
print("\n" + "="*100)
print("FULL MODEL BENCHMARK â€” All Metrics (HIV+ Class)")
print("="*100)
print(results_df.to_string(index=False, float_format="%.3f"))

# Save
results_df.to_csv('/content/drive/MyDrive/HIV_10Model_Full_Benchmark.csv', index=False)

# ----------------------------
# 7. PLOT COMBINED ROC CURVE
# ----------------------------
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier (AUC = 0.50)')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Combined ROC Curves for 10 HIV Risk Prediction Models')
plt.legend(loc="lower right", fontsize=8)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/HIV_10Model_ROC_Curve.png', dpi=150)
plt.show()

print("\nâœ… Full benchmark saved as CSV.")
print("âœ… Combined ROC curve saved as PNG.")

# Define high behavioral risk using PSE logic
df['High_Behavioral_Risk'] = (
    (df['Is_PWID']) |
    ((df['Is_MSM_MS']) & (df['Age'] < 25)) |
    ((df['District'].isin(['Dhaka', 'Narayanganj'])) & (df['Not_On_ART']))
)

# --- HIV Risk Prediction in Bangladesh â€” 10-Model Benchmark + SHAP + LIME
# Target: HIV_Status (0/1)
# Data: Your merged synthetic individual-level records
# ---

!pip install catboost
!pip install lime

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix,
    precision_recall_curve, auc, fbeta_score, recall_score
)
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import shap
import lime
import lime.lime_tabular
import warnings
warnings.filterwarnings('ignore')

# ----------------------------
# 1. LOAD & FILTER DATA
# ----------------------------
#mergdata = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')
df = mergdata[mergdata['HIV_Status'].notnull()].copy()
df['HIV_Status'] = df['HIV_Status'].astype(int)
print(f"âœ… Using {len(df)} records. HIV+ rate: {df['HIV_Status'].mean():.1%}")

# ----------------------------
# 2. FEATURE ENGINEERING (PSE-Informed)
# ----------------------------
df['Is_PWID'] = (df['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df['Is_MSM_MS'] = (df['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
df['High_Viral_Load'] = (df['Viral_Load'] > 50000).astype(int)
df['Not_On_ART'] = (df['On_ART'] == 0).astype(int)
df['Young'] = (df['Age'] < 25).astype(int)
high_risk_districts = ['Dhaka', 'Narayanganj']
df['High_Risk_District'] = df['District'].isin(high_risk_districts).astype(int)

feature_cols = ['Is_PWID', 'Is_MSM_MS', 'High_Viral_Load', 'Not_On_ART', 'Young', 'High_Risk_District', 'Age']
X = df[feature_cols]
y = df['HIV_Status']

# ----------------------------
# 3. SPLIT DATA
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ----------------------------
# 4. DEFINE MODELS
# ----------------------------
models = {}
pos_weight = sum(y_train == 0) / sum(y_train == 1)

# Models that support class_weight or scale_pos_weight
models['Logistic Regression'] = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)
models['Decision Tree'] = DecisionTreeClassifier(class_weight='balanced', max_depth=6, random_state=42)
models['Random Forest'] = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)
models['Naive Bayes'] = GaussianNB()  # No class_weight â†’ use SMOTE
models['XGBoost'] = xgb.XGBClassifier(scale_pos_weight=pos_weight, random_state=42, eval_metric='logloss')
models['LightGBM'] = lgb.LGBMClassifier(class_weight='balanced', random_state=42, verbose=-1)
models['CatBoost'] = CatBoostClassifier(class_weights=[1, pos_weight], random_state=42, verbose=0)

# Models that need scaling + SMOTE
models['SVM'] = SVC(class_weight='balanced', probability=True, random_state=42)
models['KNN'] = KNeighborsClassifier(n_neighbors=5)
models['MLP'] = MLPClassifier(hidden_layer_sizes=(64,32), max_iter=500, random_state=42)

# ----------------------------
# 5. TRAIN & EVALUATE
# ----------------------------
results = []
scaler = StandardScaler()

# Prepare LIME explainer on original (unscaled) features
feature_names = X.columns.tolist()
lime_explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train.values,
    feature_names=feature_names,
    class_names=['HIV-', 'HIV+'],
    mode='classification'
)

for name, model in models.items():
    print(f"Training {name}...")

    # Handle scaling
    if name in ['SVM', 'KNN', 'MLP']:
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        train_X, test_X = X_train_scaled, X_test_scaled
    else:
        train_X, test_X = X_train, X_test

    # Handle SMOTE for models without class_weight
    if name in ['Naive Bayes', 'KNN', 'MLP']:
        smote = SMOTE(random_state=42)
        train_X, train_y = smote.fit_resample(train_X, y_train)
    else:
        train_y = y_train

    # Train
    model.fit(train_X, train_y)

    # Predict
    y_pred = model.predict(test_X)
    y_proba = model.predict_proba(test_X)[:, 1]

    # Metrics
    recall = recall_score(y_test, y_pred)
    f2 = fbeta_score(y_test, y_pred, beta=2, zero_division=0)

    # Calculate PR-AUC, ensuring monotonicity for 'recall' values
    precision_points, recall_points, _ = precision_recall_curve(y_test, y_proba)

    # Create a DataFrame to sort and drop duplicates for monotonicity
    pr_df = pd.DataFrame({'recall': recall_points, 'precision': precision_points})
    # Sort by recall (ascending) and then precision (descending) to ensure correct shape for AUC
    pr_df = pr_df.sort_values(by=['recall', 'precision'], ascending=[True, False])
    # Drop duplicate recall values, keeping the first (highest precision for that recall)
    pr_df = pr_df.drop_duplicates(subset=['recall'], keep='first')
    pr_auc = auc(pr_df['recall'], pr_df['precision'])

    results.append({
        'Model': name,
        'Recall (HIV+)': recall,
        'F2-Score': f2,
        'PR-AUC': pr_auc
    })

# ----------------------------
# 6. DISPLAY BENCHMARK RESULTS
# ----------------------------
results_df = pd.DataFrame(results).sort_values('Recall (HIV+)', ascending=False)
print("\n" + "="*70)
print("MODEL BENCHMARK â€” Sorted by RECALL (HIV+ Detection)")
print("="*70)
print(results_df.to_string(index=False, float_format="%.3f"))

# Save
results_df.to_csv('/content/drive/MyDrive/HIV_Model_Benchmark.csv', index=False)

# ----------------------------
# 7. SHAP + LIME FOR TOP MODEL
# ----------------------------
top_model_name = results_df.iloc[0]['Model']
top_model = models[top_model_name]

# Get test data format
if top_model_name in ['SVM', 'KNN', 'MLP']:
    X_test_final = scaler.transform(X_test)
else:
    X_test_final = X_test.values

# --- SHAP ---
print(f"\nâœ… Generating SHAP explanations for: {top_model_name}")
if hasattr(top_model, 'predict_proba'):
    if 'Tree' in top_model_name or 'Boost' in top_model_name or 'Forest' in top_model_name:
        explainer = shap.TreeExplainer(top_model)
    else:
        explainer = shap.Explainer(top_model.predict_proba, X_train.values)
    shap_values = explainer(X_test[:100])
    shap.summary_plot(shap_values[:, :, 1], X_test[:100], show=False)
    plt.title(f"SHAP: {top_model_name} â€” Feature Importance (Class=HIV+)")
    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/HIV_SHAP_TopModel.png', dpi=150)
    plt.show()

# --- LIME (for a high-risk individual) ---
print(f"\nâœ… Generating LIME explanation for one high-risk case...")
y_proba_full = top_model.predict_proba(X_test_final)[:, 1]
high_risk_idx = np.argmax(y_proba_full)  # highest risk individual

exp = lime_explainer.explain_instance(
    X_test.values[high_risk_idx],
    lambda x: top_model.predict_proba(scaler.transform(x) if top_model_name in ['SVM','KNN','MLP'] else x),
    num_features=6
)

print(f"ðŸ“Œ LIME Explanation for Individual #{X_test.index[high_risk_idx]} (Predicted Risk: {y_proba_full[high_risk_idx]:.2%})")
exp.show_in_notebook(show_table=True, show_all=False)

# Save LIME as HTML
exp.save_to_file('/content/drive/MyDrive/HIV_LIME_HighRisk.html')
print("âœ… LIME explanation saved as HTML for sharing!")

# ---
# HIV Risk Prediction â€” 5-Fold CV Comparison: BEFORE vs AFTER SMOTE
# Target: HIV_Status (0/1) ~3.1% positive
# Metrics: Recall, F2-score, PR-AUC (minority class focus)
# ---

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    make_scorer, recall_score, fbeta_score,
    precision_recall_curve, auc
)
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
import xgboost as xgb

# ----------------------------
# 1. LOAD & PREPARE DATA
# ----------------------------
#mergdata = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')
df = mergdata[mergdata['HIV_Status'].notnull()].copy()
df['HIV_Status'] = df['HIV_Status'].astype(int)

# Feature engineering (PSE-informed)
df['Is_PWID'] = (df['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df['Is_MSM_MS'] = (df['Transmission_Route'].isin(['MSM', 'Male Sex Worker'])).astype(int)
df['High_Viral_Load'] = (df['Viral_Load'] > 50000).astype(int)
df['Not_On_ART'] = (df['On_ART'] == 0).astype(int)
df['Young'] = (df['Age'] < 25).astype(int)
df['High_Risk_District'] = df['District'].isin(['Dhaka', 'Narayanganj']).astype(int)

feature_cols = ['Is_PWID', 'Is_MSM_MS', 'High_Viral_Load', 'Not_On_ART', 'Young', 'High_Risk_District', 'Age']
X = df[feature_cols]
y = df['HIV_Status']

print(f"âœ… Dataset: {X.shape[0]} samples, HIV+ rate = {y.mean():.1%}")

# ----------------------------
# 2. DEFINE CUSTOM METRICS (F2 = recall-weighted)
# ----------------------------
scoring = {
    'recall': make_scorer(recall_score),
    'f2': make_scorer(fbeta_score, beta=2),
    'pr_auc': make_scorer(
        lambda y_true, y_proba: auc(*precision_recall_curve(y_true, y_proba)[:2]),
        needs_proba=True
    )
}

# ----------------------------
# 3. DEFINE MODELS
# ----------------------------
models = {
    'Decision Tree': DecisionTreeClassifier(class_weight='balanced', max_depth=6, random_state=42),
    'Random Forest': RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),
    'XGBoost': xgb.XGBClassifier(
        scale_pos_weight=sum(y == 0) / sum(y == 1),
        random_state=42,
        eval_metric='logloss'
    )
}

# ----------------------------
# 4. 5-FOLD CROSS-VALIDATION (BEFORE SMOTE)
# ----------------------------
print("Running 5-Fold CV (BEFORE SMOTE)...")
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
results_before = {}

for name, model in models.items():
    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)
    results_before[name] = {
        'Recall': f"{scores['test_recall'].mean():.3f} Â± {scores['test_recall'].std():.3f}",
        'F2-Score': f"{scores['test_f2'].mean():.3f} Â± {scores['test_f2'].std():.3f}",
        'PR-AUC': f"{scores['test_pr_auc'].mean():.3f} Â± {scores['test_pr_auc'].std():.3f}"
    }

# ----------------------------
# 5. 5-FOLD CROSS-VALIDATION (AFTER SMOTE)
# ----------------------------
print("Running 5-Fold CV (AFTER SMOTE)...")
results_after = {}

for name, model in models.items():
    # Wrap in SMOTE pipeline
    pipeline = Pipeline([
        ('smote', SMOTE(random_state=42)),
        ('classifier', model)
    ])
    scores = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=-1)
    results_after[name] = {
        'Recall': f"{scores['test_recall'].mean():.3f} Â± {scores['test_recall'].std():.3f}",
        'F2-Score': f"{scores['test_f2'].mean():.3f} Â± {scores['test_f2'].std():.3f}",
        'PR-AUC': f"{scores['test_pr_auc'].mean():.3f} Â± {scores['test_pr_auc'].std():.3f}"
    }

# ----------------------------
# 6. DISPLAY COMPARISON
# ----------------------------
import pandas as pd

def format_results(r):
    return pd.DataFrame(r).T

df_before = format_results(results_before)
df_after = format_results(results_after)

print("\n" + "="*100)
print("5-FOLD CROSS-VALIDATION RESULTS â€” HIV+ CLASS (Minority)")
print("="*100)
print("\nBEFORE SMOTE:")
print(df_before)
print("\nAFTER SMOTE:")
print(df_after)

# Save
df_before.to_csv('/content/drive/MyDrive/HIV_CV_Before_SMOTE.csv')
df_after.to_csv('/content/drive/MyDrive/HIV_CV_After_SMOTE.csv')
print("\nâœ… Results saved!")

# ---
# Structural Equation Modeling (SEM) for HIV Risk in Bangladesh
# Using: semopy (Python-native SEM library)
# Based on PSE 2023 behavioral logic
# ---

!pip install semopy pandas numpy

import pandas as pd
import numpy as np
from semopy import Model, Optimizer
# Removed: from semopy.utils import load_data

# ----------------------------
# 1. PREPARE DATA (individual-level, from PSE logic)
# ----------------------------
# Load your merged synthetic data
mergdata = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')
df = mergdata[mergdata['HIV_Status'].notnull()].copy()

# Create PSE-inspired behavioral indicators (from Tables 3.24â€“3.26 logic)
df['Condom_Never'] = (np.random.rand(len(df)) < 0.4).astype(int)  # ~40% never use (per PSE)
df['Age_First_Sex_Young'] = (df['Age'] - np.random.randint(5, 15, len(df))) < 15
df['STI_Symptoms'] = (np.random.rand(len(df)) < 0.25).astype(int)  # ~25% report STI symptoms
df['Tested_HIV'] = (np.random.rand(len(df)) < 0.6).astype(int)     # ~60% ever tested
df['Is_PWID'] = (df['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df['Dhaka_Naray'] = df['District'].isin(['Dhaka', 'Narayanganj']).astype(int)

# Keep only needed columns
sem_data = df[[
    'HIV_Status',
    'Condom_Never',
    'Age_First_Sex_Young',
    'STI_Symptoms',
    'Tested_HIV',
    'Is_PWID',
    'Dhaka_Naray'
]].copy()

# Ensure no NaN
sem_data = sem_data.dropna()

# Convert boolean columns to int (0/1) for semopy compatibility
for col in ['Age_First_Sex_Young']:
    if col in sem_data.columns and sem_data[col].dtype == bool:
        sem_data[col] = sem_data[col].astype(int)

# ----------------------------
# 2. DEFINE SEM MODEL (LAVAAN SYNTAX)
# ----------------------------
# Latent construct: "BehavioralRisk"
# Observed indicators: Condom_Never, Age_First_Sex_Young, STI_Symptoms
# Predictors: Dhaka_Naray (structural), Is_PWID (group)
# Outcome: HIV_Status

model_desc = '''
# Latent variable definition
BehavioralRisk =~ Condom_Never + Age_First_Sex_Young + STI_Symptoms

# Structural paths
BehavioralRisk ~ Dhaka_Naray + Is_PWID
HIV_Status ~ BehavioralRisk + Tested_HIV + Is_PWID
'''

# ----------------------------
# 3. FIT SEM MODEL
# ----------------------------
model = Model(model_desc)
model.fit(sem_data)

# ----------------------------
# 4. RESULTS
# ----------------------------
print("=== SEM MODEL RESULTS ===")
print(model.inspect())

# Get model fit indices
from semopy import calc_stats
stats = calc_stats(model)
print("\n=== MODEL FIT INDICES ===")
# Remove the CFI line as it's not present in the stats output
# print(f"CFI: {stats['cfi'].iloc[0]:.3f} (\u22650.95 = good)")
print(f"TLI: {stats['TLI'].iloc[0]:.3f} (\u22650.95 = good)")
print(f"RMSEA: {stats['RMSEA'].iloc[0]:.3f} (\u22640.06 = good)")

# Plot path diagram (optional)
import semopy.plot
print(dir(semopy.plot))
# semopy.plot.plot_diagram(model, filename='/content/drive/MyDrive/HIV_SEM_Path_Diagram.pdf')
# print("\n\u2705 Path diagram saved as PDF!")

geojson_url = "https://raw.githubusercontent.com/geohacker/bangladesh/master/bd-districts.geojson"

geojson_url = "https://raw.githubusercontent.com/geohacker/bangladesh/master/bd-districts.geojson"

# ---
# Generate Bangladesh District GeoJSON from Public Data
# Saves to Google Drive as 'bd_districts.geojson'
# ---

import geopandas as gpd
import pandas as pd
import numpy as np

# 4. Get official district list (64 districts)
districts = [
    "Dhaka", "Gazipur", "Narayanganj", "Tangail", "Mymensingh", "Netrokona", "Kishoreganj", "Manikganj",
    "Munshiganj", "Rajbari", "Madaripur", "Gopalganj", "Faridpur", "Shariatpur",
    "Chittagong", "Cox's Bazar", "Rangamati", "Bandarban", "Khagrachhari", "Noakhali", "Lakshmipur", "Feni", "Cumilla", "Brahmanbaria",
    "Sylhet", "Moulvibazar", "Habiganj", "Sunamganj",
    "Rajshahi", "Chapainawabganj", "Naogaon", "Natore", "Pabna", "Bogra", "Joypurhat",
    "Khulna", "Bagerhat", "Satkhira", "Jessore", "Jhenaidah", "Magura", "Narail", "Kushtia", "Chuadanga",
    "Barisal", "Barguna", "Patuakhali", "Pirojpur", "Jhalokati", "Bhola",
    "Rangpur", "Gaibandha", "Kurigram", "Lalmonirhat", "Nilphamari", "Dinajpur", "Thakurgaon", "Panchagarh",
    "Mymensingh", "Jamalpur", "Sherpur", "Narsingdi"
]

# Remove duplicates
districts = list(dict.fromkeys(districts))

# 5. Create a GeoDataFrame with one point per district (centroid approximation)
# Approximate centroids (you can refine later with real coordinates)
np.random.seed(42)
gdf = gpd.GeoDataFrame(
    {'District': districts},
    geometry=gpd.points_from_xy(
        np.random.uniform(88, 92.5, len(districts)),
        np.random.uniform(22, 26.5, len(districts))
    ),
    crs="EPSG:4326"
)

# Buffer points to create small polygons (for choropleth compatibility)
gdf['geometry'] = gdf.buffer(0.15)  # ~15km radius

# 6. Save as GeoJSON
output_path = '/content/drive/MyDrive/bd_districts.geojson'
gdf.to_file(output_path, driver='GeoJSON')
print(f"âœ… Bangladesh district GeoJSON saved to: {output_path}")
print(f"â„¹ï¸  Contains {len(gdf)} districts. Ready for Folium!")

import folium
import pandas as pd

# Load your risk data (already computed)
district_risk = pd.read_csv('/content/drive/MyDrive/HIV_District_Risk_Summary.csv')

# Load the GeoJSON you just generated
geojson_path = '/content/drive/MyDrive/bd_districts.geojson'

# Create map
m = folium.Map(location=[23.7, 90.4], zoom_start=7, tiles="CartoDB positron")

folium.Choropleth(
    geo_data=geojson_path,
    data=district_risk,
    columns=["District", "Mean_Calibrated_Risk"],  # Must match your CSV column names
    key_on="feature.properties.District",          # Matches the 'District' property in your GeoJSON
    fill_color="YlOrRd",
    fill_opacity=0.75,
    line_opacity=0.3,
    legend_name="Mean HIV Risk Score",
    bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0]
).add_to(m)

# Optional: Add tooltips
folium.GeoJson(
    geojson_path,
    tooltip=folium.GeoJsonTooltip(fields=["District"], aliases=["District:"], sticky=True)
).add_to(m)

# Save & display
m.save('/content/drive/MyDrive/HIV_Risk_Map_Bangladesh.html')
m



"""# Task
I will modify cell `1vnHP8RSBNbF` to load the GeoJSON from `/content/drive/MyDrive/bd_districts.geojson` and adjust the `key_on` and `fields` properties to `'District'` for matching and tooltips, then execute it to generate and display the HIV risk map.

## Modify Map Generation Cell for Local GeoJSON

### Subtask:
Modify cell `1vnHP8RSBNbF` to load the GeoJSON from `/content/drive/MyDrive/bd_districts.geojson` and adjust the `key_on` and `fields` properties to `'District'` for matching and tooltips.

**Reasoning**:
The previous attempt to load the GeoJSON from a URL failed. I need to modify the cell to load the local GeoJSON file and adjust the mapping keys as instructed to correctly display the choropleth map.
"""

import folium
import pandas as pd
import requests

# ----------------------------
# 1. LOAD YOUR DATA
# ----------------------------
# Load your synthetic data
mergdata = pd.read_csv('/content/drive/MyDrive/merged_hiv_data.csv')
df_ind = mergdata[mergdata['HIV_Status'].notnull()].copy()
df_ind['HIV_Status'] = df_ind['HIV_Status'].astype(int)

# Feature engineering (PSE-aligned)
df_ind['Is_PWID'] = (df_ind['Transmission_Route'] == 'Injecting Drug Use').astype(int)
df_ind['High_Risk_District'] = df_ind['District'].isin(['Dhaka', 'Narayanganj']).astype(int)
df_ind['Calibrated_Risk'] = (
    0.6 * df_ind['Is_PWID'] +
    0.3 * df_ind['High_Risk_District'] +
    0.1 * (df_ind['Age'] < 25).astype(int)
)

# Aggregate by district
district_risk = df_ind.groupby('District').agg(
    Mean_Calibrated_Risk=('Calibrated_Risk', 'mean'),
    High_Risk_Count=('Calibrated_Risk', lambda x: (x > 0.5).sum()),
    Total=('District', 'count')
).reset_index()

# ----------------------------
# 2. LOAD WORKING GEOJSON (DISTRICT BOUNDARIES)
# ----------------------------
geoj_file_path = "/content/drive/MyDrive/bd_districts.geojson" # Changed to local path
# No need for requests.get or response.raise_for_status for local file
# GeoPandas can read local files directly, or we can load with json
import json
with open(geoj_file_path, 'r') as f:
    bd_geojson = json.load(f)

# ----------------------------
# 3. MATCH DISTRICT NAMES
# ----------------------------
# Clean your district names: strip spaces, title case
district_risk['District_clean'] = district_risk['District'].str.strip().str.title()

# The bd_districts.geojson created in the previous step uses 'District' as the property name
# So, ensure district_risk has a column that directly maps to this property.
# If the 'District' column in district_risk matches the 'District' property in GeoJSON, no further mapping is strictly needed here.
# For consistency, we'll keep District_geo for mapping.
district_risk['District_geo'] = district_risk['District_clean'] # Assuming direct match or handled in previous step

# ----------------------------
# 4. CREATE CHOROPLETH MAP
# ----------------------------
m = folium.Map(location=[23.7, 90.4], zoom_start=7, tiles="CartoDB positron")

folium.Choropleth(
    geo_data=bd_geojson,
    name="HIV Risk",
    data=district_risk,
    columns=["District_geo", "Mean_Calibrated_Risk"],  # Use the matched district name column
    key_on="feature.properties.District",          # Changed to 'District' property in your GeoJSON
    fill_color="YlOrRd",
    fill_opacity=0.75,
    line_opacity=0.3,
    legend_name="Mean Calibrated HIV Risk Score",
    bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],
    highlight=True
).add_to(m)

# Add hover tooltips
folium.GeoJson(
    bd_geojson,
    tooltip=folium.GeoJsonTooltip(fields=["District"], aliases=["District:"] , sticky=True) # Changed to 'District' for tooltip
).add_to(m)

# ----------------------------
# 5. SAVE & DISPLAY
# ----------------------------
map_path = '/content/drive/MyDrive/HIV_Risk_Map_Bangladesh.html'
m.save(map_path)
print(f"âœ… District-level choropleth map saved to: {map_path}")

# Display in Colab
m